{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import maxabs_scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train and test sets\n",
    "train_tweets = []\n",
    "train_scores = []\n",
    "with open(\"training.1600000.processed.noemoticon.csv\", \"r\") as train_file:\n",
    "    trainreader = csv.reader(train_file)\n",
    "    try:\n",
    "        for row in trainreader:\n",
    "            score = int(row[0])/4\n",
    "            if score != 0.5:\n",
    "                train_tweets.append(row[5])\n",
    "                train_scores.append(score)\n",
    "    except UnicodeDecodeError:\n",
    "        print(row)\n",
    "        \n",
    "test_tweets = []\n",
    "test_scores = []\n",
    "with open(\"testdata.manual.2009.06.14.csv\", \"r\") as test_file:\n",
    "    testreader = csv.reader(test_file)\n",
    "    try:\n",
    "        for row in testreader:\n",
    "            score = int(row[0])/4\n",
    "            if score != 0.5:\n",
    "                test_tweets.append(row[5])\n",
    "                test_scores.append(score)\n",
    "    except UnicodeDecodeError:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess(tweets):\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "    REPLACE_USER = re.compile(\"@.+?\\s\")\n",
    "    tweets = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in tweets]\n",
    "    tweets = [REPLACE_USER.sub(\"@_ \", line.lower()) for line in tweets]\n",
    "    return tweets\n",
    "\n",
    "train_tweets = preprocess(train_tweets)\n",
    "test_tweets = preprocess(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@_ que me muera  \n"
     ]
    }
   ],
   "source": [
    "print(train_tweets[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features from raw text\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(train_tweets)\n",
    "X = cv.transform(train_tweets)\n",
    "X_test = cv.transform(test_tweets)\n",
    "# Normalize data\n",
    "X_scale = maxabs_scale(X)\n",
    "X_test_scale = maxabs_scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, train_scores, train_size = 0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7885725\n",
      "Accuracy for C=0.05: 0.7957125\n",
      "Accuracy for C=0.25: 0.7983575\n",
      "Accuracy for C=0.5: 0.79806\n",
      "Accuracy for C=1: 0.797245\n"
     ]
    }
   ],
   "source": [
    "# Find hyperparameters\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c, solver=\"saga\")\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8105849582172702\n"
     ]
    }
   ],
   "source": [
    "# Train model with all data\n",
    "final_model = LogisticRegression(C=0.25, solver=\"saga\")\n",
    "final_model.fit(X, train_scores)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(test_scores, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie data\n",
    "movie_tweets = json.load(open(\"movie_tweets.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detective Pikachu 0.6924287408022424\n",
      "Gemini Man 0.6057201698656581\n",
      "The Irishman 0.6363357537136467\n",
      "Angel Has Fallen 0.5734007681801666\n",
      "Hobbs & Shaw 0.7836779496613233\n",
      "Vivarium 0.6904062787399092\n",
      "Birds of Prey 0.590655869945211\n",
      "Jojo Rabbit 0.5926116692459874\n",
      "Spies in Disguise 0.7200359795857291\n",
      "Frozen II 0.5549495306836143\n",
      "Uncut Gems 0.7386042052888141\n",
      "Ad Astra 0.7152963790682016\n",
      "Klaus 0.6470385221514315\n",
      "The Two Popes 0.689480314859459\n",
      "Marriage Story 0.5990777834393655\n",
      "Avengers: Endgame 0.8944595986806599\n",
      "Trolls World Tour 0.7384290491211631\n",
      "Coffee & Kareem 0.7798542512906961\n",
      "Knives Out 0.6483327451711969\n",
      "Queen & Slim 0.6147024526372544\n"
     ]
    }
   ],
   "source": [
    "# Get average sentiment for each movie\n",
    "for movie, data in movie_tweets.items():\n",
    "    tweets = [tweet[\"text\"] for tweet in data]\n",
    "    feats = cv.transform(preprocess(tweets))\n",
    "    preds = final_model.predict_proba(feats)\n",
    "    print(movie, np.mean(preds, axis=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
